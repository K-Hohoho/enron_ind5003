{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IND5003 Enron Project\n",
    "## Contents of this Jupyter Notebook\n",
    "### Dataset\n",
    "Dataset from Prof: \n",
    "(https://www.cs.cmu.edu/~./enron/)\n",
    "- Unstructured Dataset containing raw text in the form of emails\n",
    "**Make sure that the dataset 'maildir' is in the same directory as your project on your own system. Else this would not work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to this Project\n",
    "\n",
    "### Research Questions\n",
    "Thought of Research Questions to provide a narrative and storyline in our analysis of the Enron Email Corpus\n",
    "\n",
    "We would be taking a broad to narrow approach in terms of the narrative that we are looking to create. \n",
    "\n",
    "Some research questions that we would be hoping to analyse in this project are:\n",
    "1. Are there any topical shifts that we can identify prior, leading up to and after the fraud has been exposed?\n",
    "2. Can we detect sentiment shifts and anomalies in communication patterns leading up to, during and after the exposure of the fraud?\n",
    "3. Identification of key individuals involved in the key discussions and anomalies in their comms patterns\n",
    "\n",
    "#### Timeline\n",
    "\n",
    "We have an intention to split our analysis into 3 defined timeframes:\n",
    "    1. Pre-Crisis \n",
    "    2. During Crisis\n",
    "    3. Post Crisis\n",
    "    [GUYS WE NEED TO THINK OF THE DATES TO SPLIT THE TIMEFRAMES INTO. I WAS THINKING WE CAN FOLLOW JUST THE TIMELINE. THIS PART DEFINITELY HAVE TO STATE ASSUMPTIONS]\n",
    "\n",
    "These research questions would be answered using a variety of NLP and Unsupervised Learning Techniques. \n",
    "\n",
    "[GUYS WE NEED TO THINK OF THE TECHNIQUES]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Steps to Tackle this Project\n",
    "1. Data Extraction\n",
    "2. Data Cleaning & Preprocessing\n",
    "3. Sender Frequency Analysis\n",
    "4. Visualisation\n",
    "    - Word Cloud & Bar Charts for the Top Senders (20%)\n",
    "    - Network Graph\n",
    "5. Unsupervised Techniques\n",
    "    - LDA Topic Modeling - Find out key topics from the top 20% of senders\n",
    "    - Temporal Analysis - Segment the emails by quarters. Look at the way communication changes over time.\n",
    "    - Hierarchical Clustering - Group senders based on communication patterns\n",
    "    - Anomaly Detection - Look for outliers and abnormal communication patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Data Extraction\n",
    "- Extract the emails from the unstructured raw folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries required for Section 1\n",
    "import os # Required for directory traversal\n",
    "import pandas as pd\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maildir path to the respective paths in your system \n",
    "# ! Note that maildir should be in the same directory as your project on your own system, would change if you are using windows\n",
    "maildir_path = '/Users/Dylan/Documents/IND5003/Projects/maildir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arnold-j', 'phanis-s', 'lavorato-j', 'stclair-c', 'townsend-j', 'forney-j', 'symes-k', 'reitmeyer-j', 'hyatt-k', 'steffes-j', 'kaminski-v', 'wolfe-j', 'mcconnell-m', 'skilling-j', 'zipper-a', 'shively-h', 'donoho-l', 'sanchez-m', 'delainey-d', 'germany-c', 'whalley-l', 'buy-r', 'harris-s', 'tholt-j', 'cash-m', 'sanders-r', '.DS_Store', 'staab-t', 'semperger-c', 'mccarty-d', 'mclaughlin-e', 'ring-a', 'stokley-c', 'hain-m', 'weldon-c', 'ring-r', 'farmer-d', 'sager-e', 'zufferli-j', 'ybarbo-p', 'watson-k', 'dasovich-j', 'arora-h', 'slinger-r', 'martin-t', 'storey-g', 'ruscitti-k', 'shankman-j', 'schwieger-j', 'perlingiere-d', 'saibi-e', 'griffith-j', 'meyers-a', 'grigsby-m', 'taylor-m', 'rapp-b', 'causholli-m', 'derrick-j', 'bass-e', 'south-s', 'salisbury-h', 'beck-s', 'tycholiz-b', 'shackleton-s', 'kitchen-l', 'merriss-s', 'blair-l', 'quenet-j', 'lokey-t', 'williams-j', 'panus-s', 'gang-l', 'hendrickson-s', 'schoolcraft-d', 'mann-k', 'kuykendall-t', 'allen-p', 'giron-d', 'lewis-a', 'jones-t', 'carson-m', 'stepenovitch-j', 'whitt-m', 'love-p', 'whalley-g', 'presto-k', 'scott-s', 'crandell-s', 'rodrique-r', 'white-s', 'motley-m', 'sturm-f', 'dean-c', 'keiser-k', 'shapiro-r', 'corman-s', 'pereira-s', 'campbell-l', 'richey-c', 'ward-k', 'dickson-s', 'rogers-b', 'nemec-g', 'hayslett-r', 'haedicke-m', 'mckay-j', 'gay-r', 'brawner-s', 'lucci-p', 'king-j', 'geaccone-t', 'guzman-m', 'mckay-b', 'hyvl-d', 'williams-w3', 'davis-d', 'thomas-p', 'linder-e', 'heard-m', 'hodge-j', 'pimenov-v', 'neal-s', 'fossum-d', 'baughman-d', 'smith-m', 'mims-thurston-p', 'bailey-s', 'fischer-m', 'dorland-c', 'ermis-f', 'may-l', 'platter-p', 'keavey-p', 'cuilla-m', 'parks-j', 'lokay-m', 'kean-s', 'quigley-d', 'horton-s', 'benson-r', 'solberg-g', 'badeer-r', 'lay-k', 'gilbertsmith-d', 'lenhart-m', 'swerzbin-m', 'hernandez-j', 'holst-k', 'maggi-m', 'donohoe-t', 'scholtes-d']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all the directories in the maildir for sanity check\n",
    "maildir_list = os.listdir(maildir_path)\n",
    "print(maildir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_email(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'rb') as f:\n",
    "#             msg = BytesParser(policy=policy.default).parse(f)\n",
    "        \n",
    "#         # Extract fields from the email\n",
    "#         email_from = msg['From']\n",
    "#         email_to = msg['To']\n",
    "#         email_date = msg['Date']\n",
    "#         email_subject = msg['Subject']\n",
    "#         email_body = msg.get_body(preferencelist=('plain')).get_content() if msg.get_body(preferencelist=('plain')) else ''\n",
    "        \n",
    "#         return [email_from, email_to, email_date, email_subject, email_body]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error parsing file {file_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def batch_iterator(iterator, batch_size):\n",
    "#     \"\"\"Yield batches of specified size from an iterator.\"\"\"\n",
    "#     while True:\n",
    "#         batch = list(islice(iterator, batch_size))\n",
    "#         if not batch:\n",
    "#             break\n",
    "#         yield batch\n",
    "\n",
    "# def load_emails(maildir_path, batch_size=10, max_emails=50):\n",
    "#     email_data = []\n",
    "#     file_paths = []\n",
    "\n",
    "#     # Walk through the directory to collect file paths\n",
    "#     for root, dirs, files in os.walk(maildir_path):\n",
    "#         for file in files:\n",
    "#             if file == '.DS_Store' or file.startswith('.'):\n",
    "#                 continue  # Skip system files and hidden files\n",
    "#             file_paths.append(os.path.join(root, file))\n",
    "#             if len(file_paths) >= max_emails:\n",
    "#                 break\n",
    "#         if len(file_paths) >= max_emails:\n",
    "#             break\n",
    "\n",
    "#     # Process emails in batches\n",
    "#     for batch in batch_iterator(iter(file_paths), batch_size):\n",
    "#         batch_data = []\n",
    "#         for file_path in batch:\n",
    "#             result = parse_email(file_path)\n",
    "#             if result is not None:\n",
    "#                 batch_data.append(result)\n",
    "        \n",
    "#         # Append batch data to the main list\n",
    "#         email_data.extend(batch_data)\n",
    "\n",
    "#     # Create a DataFrame from the extracted data\n",
    "#     df = pd.DataFrame(email_data, columns=['From', 'To', 'Date', 'Subject', 'Body'])\n",
    "#     return df\n",
    "\n",
    "# # Load and parse emails\n",
    "# emails_df = load_emails(maildir_path, batch_size=10, max_emails=50)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(emails_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data into a Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing file /Users/Dylan/Documents/IND5003/Projects/maildir/kitchen-l/sent_items/24.: 'ValueTerminal' object does not support item assignment\n",
      "Error parsing file /Users/Dylan/Documents/IND5003/Projects/maildir/kitchen-l/_americas/netco_eol/83.: 'ValueTerminal' object does not support item assignment\n",
      "Error parsing file /Users/Dylan/Documents/IND5003/Projects/maildir/kitchen-l/_americas/netco_eol/82.: 'ValueTerminal' object does not support item assignment\n",
      "Error parsing file /Users/Dylan/Documents/IND5003/Projects/maildir/kitchen-l/_americas/esvl/87.: 'ValueTerminal' object does not support item assignment\n",
      "Error parsing file /Users/Dylan/Documents/IND5003/Projects/maildir/kitchen-l/_americas/netco_restart/3.: 'ValueTerminal' object does not support item assignment\n",
      "                        From  \\\n",
      "0            msagel@home.com   \n",
      "1    slafontaine@globalp.com   \n",
      "2    iceoperations@intcx.com   \n",
      "3  jeff.youngflesh@enron.com   \n",
      "4  caroline.abramo@enron.com   \n",
      "\n",
      "                                                  To  \\\n",
      "0                                  jarnold@enron.com   \n",
      "1                              john.arnold@enron.com   \n",
      "2  icehelpdesk@intcx.com, internalmarketing@intcx...   \n",
      "3  anthony.gilmore@enron.com, colleen.koenig@enro...   \n",
      "4                             mike.grigsby@enron.com   \n",
      "\n",
      "                              Date  \\\n",
      "0  Thu, 16 Nov 2000 09:30:00 -0800   \n",
      "1  Fri, 08 Dec 2000 05:05:00 -0800   \n",
      "2  Tue, 15 May 2001 09:43:00 -0700   \n",
      "3  Mon, 27 Nov 2000 01:49:00 -0800   \n",
      "4  Tue, 12 Dec 2000 09:33:00 -0800   \n",
      "\n",
      "                                             Subject  \\\n",
      "0                                             Status   \n",
      "1                                 re:summer inverses   \n",
      "2                      The WTI Bullet swap contracts   \n",
      "3  Invitation: EBS/GSS Meeting w/Bristol Babcock ...   \n",
      "4                                       Harvard Mgmt   \n",
      "\n",
      "                                                Body  \n",
      "0  John:\\n?\\nI'm not really sure what happened be...  \n",
      "1  i suck-hope youve made more money in natgas la...  \n",
      "2   Hi,\\n\\n\\n  Following the e-mail you have rece...  \n",
      "3  Conference Room TBD.  \\n\\nThis meeting will be...  \n",
      "4  Mike- I have their trader coming into the offi...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ! This is a very large dataset and will take a long time to run\n",
    "# ! DO NOT RUN THIS FOR FUN UNLESS YOU WANT YOUR COMPUTER TO CRASH\n",
    "def parse_email(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            msg = BytesParser(policy=policy.default).parse(f)\n",
    "        \n",
    "        # Extract fields from the email\n",
    "        email_from = msg['From']\n",
    "        email_to = msg['To']\n",
    "        email_date = msg['Date']\n",
    "        email_subject = msg['Subject']\n",
    "        email_body = msg.get_body(preferencelist=('plain')).get_content() if msg.get_body(preferencelist=('plain')) else ''\n",
    "        \n",
    "        return [email_from, email_to, email_date, email_subject, email_body]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def batch_iterator(iterator, batch_size):\n",
    "    \"\"\"Yield batches of specified size from an iterator.\"\"\"\n",
    "    while True:\n",
    "        batch = list(islice(iterator, batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "def load_emails(maildir_path, batch_size=1000):\n",
    "    email_data = []\n",
    "    file_paths = []\n",
    "\n",
    "    # Walk through the directory to collect file paths\n",
    "    for root, dirs, files in os.walk(maildir_path):\n",
    "        for file in files:\n",
    "            if file == '.DS_Store' or file.startswith('.'):\n",
    "                continue  # Skip system files and hidden files\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "\n",
    "    # Process emails in batches\n",
    "    for batch in batch_iterator(iter(file_paths), batch_size):\n",
    "        batch_data = []\n",
    "        for file_path in batch:\n",
    "            result = parse_email(file_path)\n",
    "            if result is not None:\n",
    "                batch_data.append(result)\n",
    "        \n",
    "        # Append batch data to the main list\n",
    "        email_data.extend(batch_data)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(email_data, columns=['From', 'To', 'Date', 'Subject', 'Body'])\n",
    "    return df\n",
    "\n",
    "# Load and parse emails\n",
    "emails_df = load_emails(maildir_path, batch_size=1000)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(emails_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert emails_df to a CSV file\n",
    "# Save the DataFrame as a CSV file in the specified directory\n",
    "\n",
    "#emails_df.to_csv('/Users/Dylan/Documents/IND5003/Projects/emails_uncleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        From  \\\n",
      "0            msagel@home.com   \n",
      "1    slafontaine@globalp.com   \n",
      "2    iceoperations@intcx.com   \n",
      "3  jeff.youngflesh@enron.com   \n",
      "4  caroline.abramo@enron.com   \n",
      "\n",
      "                                                  To  \\\n",
      "0                                  jarnold@enron.com   \n",
      "1                              john.arnold@enron.com   \n",
      "2  icehelpdesk@intcx.com, internalmarketing@intcx...   \n",
      "3  anthony.gilmore@enron.com, colleen.koenig@enro...   \n",
      "4                             mike.grigsby@enron.com   \n",
      "\n",
      "                              Date  \\\n",
      "0  Thu, 16 Nov 2000 09:30:00 -0800   \n",
      "1  Fri, 08 Dec 2000 05:05:00 -0800   \n",
      "2  Tue, 15 May 2001 09:43:00 -0700   \n",
      "3  Mon, 27 Nov 2000 01:49:00 -0800   \n",
      "4  Tue, 12 Dec 2000 09:33:00 -0800   \n",
      "\n",
      "                                             Subject  \\\n",
      "0                                             Status   \n",
      "1                                 re:summer inverses   \n",
      "2                      The WTI Bullet swap contracts   \n",
      "3  Invitation: EBS/GSS Meeting w/Bristol Babcock ...   \n",
      "4                                       Harvard Mgmt   \n",
      "\n",
      "                                                Body  \n",
      "0  John:\\n?\\nI'm not really sure what happened be...  \n",
      "1  i suck-hope youve made more money in natgas la...  \n",
      "2   Hi,\\n\\n\\n  Following the e-mail you have rece...  \n",
      "3  Conference Room TBD.  \\n\\nThis meeting will be...  \n",
      "4  Mike- I have their trader coming into the offi...  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file back into a DataFrame\n",
    "\n",
    "# PLEASE CHANGE IT TO YOUR OWN DIRECTORY IN YOUR OWN SYSTEM \n",
    "\n",
    "# Load the CSV file back into a DataFrame\n",
    "\n",
    "# PLEASE CHANGE IT TO YOUR OWN DIRECTORY IN YOUR OWN SYSTEM \n",
    "\n",
    "enron_uncleaned_emails = pd.read_csv('/Users/Dylan/Documents/IND5003/Projects/enron_emails_uncleaned.csv')\n",
    "print(enron_uncleaned_emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            From  \\\n",
      "617     louise.kitchen@enron.com   \n",
      "874     louise.kitchen@enron.com   \n",
      "910     louise.kitchen@enron.com   \n",
      "926     louise.kitchen@enron.com   \n",
      "5072    louise.kitchen@enron.com   \n",
      "...                          ...   \n",
      "503415  louise.kitchen@enron.com   \n",
      "503507  louise.kitchen@enron.com   \n",
      "509732  louise.kitchen@enron.com   \n",
      "509790  louise.kitchen@enron.com   \n",
      "509829  louise.kitchen@enron.com   \n",
      "\n",
      "                                                       To  \\\n",
      "617                                 john.arnold@enron.com   \n",
      "874     tim.belden@enron.com, f..calger@enron.com, m.....   \n",
      "910     wes.colwell@enron.com, georgeanne.hodges@enron...   \n",
      "926                                    c..bland@enron.com   \n",
      "5072                              john.lavorato@enron.com   \n",
      "...                                                   ...   \n",
      "503415  rob.milnthorp@enron.com, f..calger@enron.com, ...   \n",
      "503507  rob.milnthorp@enron.com, f..calger@enron.com, ...   \n",
      "509732  k..allen@enron.com, john.arnold@enron.com, har...   \n",
      "509790  rob.milnthorp@enron.com, f..calger@enron.com, ...   \n",
      "509829  rob.milnthorp@enron.com, f..calger@enron.com, ...   \n",
      "\n",
      "                                   Date  \\\n",
      "617     Wed, 24 Oct 2001 11:05:03 -0700   \n",
      "874     Thu, 27 Dec 2001 14:58:02 -0800   \n",
      "910     Mon, 31 Dec 2001 10:53:43 -0800   \n",
      "926     Thu, 27 Sep 2001 06:24:25 -0700   \n",
      "5072    Tue, 23 Oct 2001 07:24:27 -0700   \n",
      "...                                 ...   \n",
      "503415  Wed, 06 Feb 2002 08:03:03 -0800   \n",
      "503507  Tue, 05 Feb 2002 15:08:44 -0800   \n",
      "509732  Wed, 07 Nov 2001 16:36:23 -0800   \n",
      "509790  Tue, 05 Feb 2002 19:08:44 -0800   \n",
      "509829  Wed, 06 Feb 2002 12:03:03 -0800   \n",
      "\n",
      "                                                 Subject  \\\n",
      "617                           Don't need to call me back   \n",
      "874                        Re-start/Integration Planning   \n",
      "910                                                NETCO   \n",
      "926     FW: Fantastic Friday/Super Saturday Interviewers   \n",
      "5072     FW: Management Conference - Business Unit Panel   \n",
      "...                                                  ...   \n",
      "503415                                 YOU HAVE 48 HOURS   \n",
      "503507                 Commercial Re-start Sub-Committee   \n",
      "509732                                          Baby Boy   \n",
      "509790                 Commercial Re-start Sub-Committee   \n",
      "509829                                 YOU HAVE 48 HOURS   \n",
      "\n",
      "                                                     Body  \n",
      "617            Sorry I completely forgot it was Wednesday  \n",
      "874     We have for the last couple of weeks started t...  \n",
      "910     The New Year has arrived and we really to fina...  \n",
      "926     \\nTed,\\n\\nThe people included in the cc: are t...  \n",
      "5072    ?????\\n\\n\\n----Original Message-----\\nFrom: \\t...  \n",
      "...                                                   ...  \n",
      "503415  This is not a circular and you will not get an...  \n",
      "503507  Following this morning's meeting, we have agre...  \n",
      "509732  \\nJack Anthony Lavorato just arrived weighing ...  \n",
      "509790  Following this morning's meeting, we have agre...  \n",
      "509829  This is not a circular and you will not get an...  \n",
      "\n",
      "[1752 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find \"kitchen\" in the column \"From\"\n",
    "\n",
    "# This is to determine that there are still emails sent from louise kitchen despite the original parsing error due to the encoding of the email\n",
    "kitchen_emails = enron_uncleaned_emails[enron_uncleaned_emails['From'].str.contains('kitchen', case=False, na=False)]\n",
    "print(kitchen_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preprocessing\n",
    "### Start with the Cleaning\n",
    "* Check for any nulls\n",
    "* Drop the missing values\n",
    "* Remove the duplicates\n",
    "* Format the dates \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column  Missing Values\n",
      "0     From               0\n",
      "1       To           21847\n",
      "2     Date               0\n",
      "3  Subject           19187\n",
      "4     Body               0\n"
     ]
    }
   ],
   "source": [
    "# Check for Nulls in Each Column\n",
    "missing_values = enron_uncleaned_emails.isnull().sum()\n",
    "missing_values_df = pd.DataFrame({'Column': missing_values.index, 'Missing Values': missing_values.values})\n",
    "print(missing_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517396</td>\n",
       "      <td>495549</td>\n",
       "      <td>517396</td>\n",
       "      <td>498209</td>\n",
       "      <td>517396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20326</td>\n",
       "      <td>58556</td>\n",
       "      <td>224119</td>\n",
       "      <td>159286</td>\n",
       "      <td>249020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>kay.mann@enron.com</td>\n",
       "      <td>pete.davis@enron.com</td>\n",
       "      <td>Wed, 27 Jun 2001 16:02:00 -0700</td>\n",
       "      <td>RE:</td>\n",
       "      <td>As you know, Enron Net Works (ENW) and Enron G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16735</td>\n",
       "      <td>9155</td>\n",
       "      <td>1118</td>\n",
       "      <td>6477</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      From                    To  \\\n",
       "count               517396                495549   \n",
       "unique               20326                 58556   \n",
       "top     kay.mann@enron.com  pete.davis@enron.com   \n",
       "freq                 16735                  9155   \n",
       "\n",
       "                                   Date Subject  \\\n",
       "count                            517396  498209   \n",
       "unique                           224119  159286   \n",
       "top     Wed, 27 Jun 2001 16:02:00 -0700     RE:   \n",
       "freq                               1118    6477   \n",
       "\n",
       "                                                     Body  \n",
       "count                                              517396  \n",
       "unique                                             249020  \n",
       "top     As you know, Enron Net Works (ENW) and Enron G...  \n",
       "freq                                                  112  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the DataFrame\n",
    "enron_uncleaned_emails.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out the missing values with empty strings\n",
    "enron_cleaned_emails = enron_uncleaned_emails.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column  Missing Values\n",
      "0     From               0\n",
      "1       To               0\n",
      "2     Date               0\n",
      "3  Subject               0\n",
      "4     Body               0\n"
     ]
    }
   ],
   "source": [
    "# Post cleaning Check\n",
    "missing_values_check = enron_cleaned_emails.isnull().sum()\n",
    "missing_values_df_check = pd.DataFrame({'Column': missing_values_check.index, 'Missing Values': missing_values_check.values})\n",
    "print(missing_values_df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517396</td>\n",
       "      <td>517396</td>\n",
       "      <td>517396</td>\n",
       "      <td>517396</td>\n",
       "      <td>517396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20326</td>\n",
       "      <td>58557</td>\n",
       "      <td>224119</td>\n",
       "      <td>159287</td>\n",
       "      <td>249020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>kay.mann@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Wed, 27 Jun 2001 16:02:00 -0700</td>\n",
       "      <td></td>\n",
       "      <td>As you know, Enron Net Works (ENW) and Enron G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16735</td>\n",
       "      <td>21847</td>\n",
       "      <td>1118</td>\n",
       "      <td>19187</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      From      To                             Date Subject  \\\n",
       "count               517396  517396                           517396  517396   \n",
       "unique               20326   58557                           224119  159287   \n",
       "top     kay.mann@enron.com          Wed, 27 Jun 2001 16:02:00 -0700           \n",
       "freq                 16735   21847                             1118   19187   \n",
       "\n",
       "                                                     Body  \n",
       "count                                              517396  \n",
       "unique                                             249020  \n",
       "top     As you know, Enron Net Works (ENW) and Enron G...  \n",
       "freq                                                  112  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the cleaned DataFrame\n",
    "enron_cleaned_emails.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From running the code above, the output would show that there are 249020 emails with unique bodies out of the 517396 emails. \n",
    "    * This means that ~51.9% of emails in the uncleaned dataframe are not unique\n",
    "    * This would ensure that the subsequent analytical metrics (when performing LDA, TFIDF, Word2vec) are not inflated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>249020</td>\n",
       "      <td>249020</td>\n",
       "      <td>249020</td>\n",
       "      <td>249020</td>\n",
       "      <td>249020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20129</td>\n",
       "      <td>58069</td>\n",
       "      <td>219084</td>\n",
       "      <td>158462</td>\n",
       "      <td>249020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>Wed, 27 Jun 2001 16:02:00 -0700</td>\n",
       "      <td></td>\n",
       "      <td>John:\\n?\\nI'm not really sure what happened be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5486</td>\n",
       "      <td>9024</td>\n",
       "      <td>1118</td>\n",
       "      <td>8577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           From      To                             Date  \\\n",
       "count                    249020  249020                           249020   \n",
       "unique                    20129   58069                           219084   \n",
       "top     jeff.dasovich@enron.com          Wed, 27 Jun 2001 16:02:00 -0700   \n",
       "freq                       5486    9024                             1118   \n",
       "\n",
       "       Subject                                               Body  \n",
       "count   249020                                             249020  \n",
       "unique  158462                                             249020  \n",
       "top             John:\\n?\\nI'm not really sure what happened be...  \n",
       "freq      8577                                                  1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate emails based on the 'Body' column, keeping only the first occurrence\n",
    "enron_cleaned_emails_body_unique = enron_cleaned_emails.drop_duplicates(subset=['Body'], keep='first')\n",
    "\n",
    "# Describe the DataFrame after removing duplicates\n",
    "enron_cleaned_emails_body_unique.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Dasovich sent 5486 emails.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27219</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>d..steffes@enron.com</td>\n",
       "      <td>Tue, 23 Oct 2001 14:25:50 -0700</td>\n",
       "      <td>RE:</td>\n",
       "      <td>thanks.\\n\\n -----Original Message-----\\nFrom: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27277</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>ginger.dernehl@enron.com, d..steffes@enron.com...</td>\n",
       "      <td>Wed, 17 Oct 2001 14:43:57 -0700</td>\n",
       "      <td>RE: Golf - November Direct Report Meeting</td>\n",
       "      <td>Yes.\\n\\n -----Original Message-----\\nFrom: \\tD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27332</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>d..steffes@enron.com, susan.mara@enron.com</td>\n",
       "      <td>Tue, 23 Oct 2001 17:02:14 -0700</td>\n",
       "      <td>FW: Stipulation Comments</td>\n",
       "      <td>I asked Mike Day to make sure that we were kep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27334</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>d..steffes@enron.com, susan.mara@enron.com</td>\n",
       "      <td>Mon, 22 Oct 2001 11:52:32 -0700</td>\n",
       "      <td>FW: Angelides Oct. 19th Letter to L. Lynch Urg...</td>\n",
       "      <td>FYI.  Here's a note I sent to the large custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27369</th>\n",
       "      <td>jeff.dasovich@enron.com</td>\n",
       "      <td>c..williams@enron.com</td>\n",
       "      <td>Fri, 26 Oct 2001 11:28:06 -0700</td>\n",
       "      <td>RE: Edison meet and confer call</td>\n",
       "      <td>Let's try this.  It's all inter-related.  PG&amp;E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          From  \\\n",
       "27219  jeff.dasovich@enron.com   \n",
       "27277  jeff.dasovich@enron.com   \n",
       "27332  jeff.dasovich@enron.com   \n",
       "27334  jeff.dasovich@enron.com   \n",
       "27369  jeff.dasovich@enron.com   \n",
       "\n",
       "                                                      To  \\\n",
       "27219                               d..steffes@enron.com   \n",
       "27277  ginger.dernehl@enron.com, d..steffes@enron.com...   \n",
       "27332         d..steffes@enron.com, susan.mara@enron.com   \n",
       "27334         d..steffes@enron.com, susan.mara@enron.com   \n",
       "27369                              c..williams@enron.com   \n",
       "\n",
       "                                  Date  \\\n",
       "27219  Tue, 23 Oct 2001 14:25:50 -0700   \n",
       "27277  Wed, 17 Oct 2001 14:43:57 -0700   \n",
       "27332  Tue, 23 Oct 2001 17:02:14 -0700   \n",
       "27334  Mon, 22 Oct 2001 11:52:32 -0700   \n",
       "27369  Fri, 26 Oct 2001 11:28:06 -0700   \n",
       "\n",
       "                                                 Subject  \\\n",
       "27219                                                RE:   \n",
       "27277          RE: Golf - November Direct Report Meeting   \n",
       "27332                           FW: Stipulation Comments   \n",
       "27334  FW: Angelides Oct. 19th Letter to L. Lynch Urg...   \n",
       "27369                    RE: Edison meet and confer call   \n",
       "\n",
       "                                                    Body  \n",
       "27219  thanks.\\n\\n -----Original Message-----\\nFrom: ...  \n",
       "27277  Yes.\\n\\n -----Original Message-----\\nFrom: \\tD...  \n",
       "27332  I asked Mike Day to make sure that we were kep...  \n",
       "27334  FYI.  Here's a note I sent to the large custom...  \n",
       "27369  Let's try this.  It's all inter-related.  PG&E...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # When running the code block above, i observed that jeff dasovich sent the most emails. \n",
    "# # Now i want to explore the number of emails he sent\n",
    "# # Filter emails where 'From' is 'jeff.dasovich@enron.com'\n",
    "# jeff_emails = enron_cleaned_emails_body_unique[enron_cleaned_emails_body_unique['From'] == 'jeff.dasovich@enron.com']\n",
    "\n",
    "# # Count the number of emails he sent\n",
    "# jeff_emails_count = jeff_emails.shape[0]\n",
    "\n",
    "# # Display the count\n",
    "# print(f\"Jeff Dasovich sent {jeff_emails_count} emails.\")\n",
    "\n",
    "# # Display the first few rows of Jeff's emails\n",
    "# jeff_emails.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ind5003",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
